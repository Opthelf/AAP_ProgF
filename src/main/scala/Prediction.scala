package projet
import projet.DataReader
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.regression.{LinearRegression, DecisionTreeRegressor, RandomForestRegressor}
import org.apache.spark.ml.evaluation.RegressionEvaluator
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
object Prediction {
  def main(args: Array[String]): Unit = {

    val spark = DataReader.spark
    val auberml = DataReader.auberml
    auberml.filter("Indicateur_Pollution_Global > 1").show()

    val windowSpec = Window.orderBy("DATE/HEURE")

    val dfEnhanced = auberml
      .withColumn("heure_jour", hour(col("DATE/HEURE")))
      .withColumn("mois", month(col("DATE/HEURE")))
      .withColumn("jour_semaine", dayofweek(col("DATE/HEURE"))) // Bonus : Lundi vs Dimanche
      // C'est ici qu'on cr√©e la colonne magique :
      .withColumn("pollution_precedente", lag("Indicateur_Pollution_Global", 1).over(windowSpec))

      // On nettoie les trous (la toute premi√®re ligne n'a pas de "pr√©c√©dent", elle devient null)
      .na.drop()

    val assembler = new VectorAssembler()
      .setInputCols(Array("heure_jour", "mois", "jour_semaine", "TEMP", "HUMI", "pollution_precedente"))
      .setOutputCol("features")

    val final_df = assembler.transform(dfEnhanced)
      .withColumnRenamed("Indicateur_Pollution_Global", "label")
    println(final_df.count())
    val Array(trainData, testData) = final_df.randomSplit(Array(0.8, 0.2), seed = 43L)

    println(s"Donn√©es d'entra√Ænement : ${trainData.count()} lignes")
    println(s"Donn√©es de test : ${testData.count()} lignes")

    // 3. ENTRA√éNEMENT DES MOD√àLES

    // --- Mod√®le A : R√©gression Lin√©aire (La base) ---
    println("\n--- 1. R√©gression Lin√©aire ---")
    val lr = new LinearRegression().setLabelCol("label").setFeaturesCol("features")
    val lrModel = lr.fit(trainData)
    val lrPred = lrModel.transform(testData)

    // --- Mod√®le B : Arbre de D√©cision (Capable de voir les pics non-lin√©aires) ---
    println("--- 2. Arbre de D√©cision ---")
    val dt = new DecisionTreeRegressor().setLabelCol("label").setFeaturesCol("features")
    val dtModel = dt.fit(trainData)
    val dtPred = dtModel.transform(testData)

    // --- Mod√®le C : For√™t Al√©atoire (Le plus robuste) ---
    println("--- 3. For√™t Al√©atoire ---")
    val rf = new RandomForestRegressor().setLabelCol("label").setFeaturesCol("features").setNumTrees(50)
    val rfModel = rf.fit(trainData)
    val rfPred = rfModel.transform(testData)

    // 4. √âVALUATION (Comparaison des RMSE)
    val evaluator = new RegressionEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("rmse")

    val rmseLR = evaluator.evaluate(lrPred)
    val rmseDT = evaluator.evaluate(dtPred)
    val rmseRF = evaluator.evaluate(rfPred)

    println("\n=== üèÜ R√âSULTATS (Erreur Moyenne) ===")
    println(f"R√©gression Lin√©aire : $rmseLR%.4f")
    println(f"Arbre de D√©cision   : $rmseDT%.4f")
    println(f"For√™t Al√©atoire     : $rmseRF%.4f")

    // 5. EXEMPLE DE PR√âDICTION CONCR√àTE
    // On regarde ce que la For√™t pr√©dit pour une des lignes de test
    println("\n--- Exemple R√©el vs Pr√©diction (For√™t) ---")
    rfPred.select("heure_jour", "TEMP", "label", "prediction").show(20)
  }

}